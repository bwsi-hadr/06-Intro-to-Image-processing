{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing\n",
    "This lesson will go over how to work with image data, extract information, and perform basic operations and transformations on images.\n",
    "\n",
    "We'll be using primarily the [Pillow](https://pillow.readthedocs.io/en/stable/index.html) and [opencv](https://opencv.org/) libraries.\n",
    "\n",
    "Pillow is a fork of the older, no-longer maintained PIL (python imaging library) package. It provides base classes for representing image data, and some convenience helper functions and dictionaries.\n",
    "\n",
    "OpenCV is a powerful image processing library. It is originally a C++ library, but we will be using the python bindings to call it in python. One important quirk of OpenCV is that **it represents image channels in BGR**, i.e. the first channel is Blue, whereas most other image representations (including PIL) use RGB, where the first channel is Red. Thus, you must make sure to switch up the order of channels when converting between PIL and opencv. \n",
    "(_The reason that opencv uses BGR is that old windows systems used to represent images in BGR, and when opencv was created, they followed that convention_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL # Python Image Library (pillow)\n",
    "from PIL.ExifTags import TAGS, GPSTAGS # dictionaries for exiftags and gpstags names\n",
    "import cv2 as cv # opencv package\n",
    "try:\n",
    "  import piexif\n",
    "  import piexif.helper\n",
    "except:\n",
    "  !pip install piexif\n",
    "  import piexif\n",
    "  import piexif.helper\n",
    "\n",
    "\n",
    "import cv2\n",
    "import pathlib # standard library package for working with file paths\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'course/06-images'\n",
    "!ls {image_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pathlib Path object\n",
    "# pathlib provides functions that make it easier to operate with file paths\n",
    "image_folder = pathlib.Path('~/course/06-images').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterdir gives an iterator for all of the items within a pathlib Path directory\n",
    "# get list of files that are jpg or png\n",
    "compatible_imgs = [x for x in image_folder.iterdir() \n",
    "                   if ((x.suffix.lower() == '.jpg') \n",
    "                       or (x.suffix.lower() == '.png'))]\n",
    "\n",
    "compatible_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_image_path = np.random.choice(compatible_imgs)\n",
    "random_img = PIL.Image.open(random_image_path)\n",
    "print(random_image_path)\n",
    "random_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_img_exif = random_img._getexif()\n",
    "random_img_exif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing EXIF\n",
    "The dictionary has numeric codes for keys. For human readability, it's convenient to use the text descriptions as the keys.\n",
    "\n",
    "There are a few lookup dictionaries that can be used to find the text descriptions. We've imported them as TAGS and GPSTAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPSTAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's some functions to parse the exif data and convert them to decimal format\n",
    "def parse_exif(exif_dict):\n",
    "  human_readable = {}\n",
    "  for k, v in exif_dict.items():\n",
    "    text_key = TAGS[k]\n",
    "    if type(v) == tuple and len(v)==2:\n",
    "      v = divide_tuple(v)\n",
    "    if k == 34853: # GPS info field\n",
    "      human_readable[text_key] = parse_gps(v)\n",
    "    elif not ((text_key == 'UserComment') or (text_key == 'MakerNote')):\n",
    "      human_readable[text_key] = v\n",
    "  return human_readable\n",
    "      \n",
    "def parse_gps(gps_dict):\n",
    "  readable_gps = {}\n",
    "  for k,v in gps_dict.items():\n",
    "    text_key = GPSTAGS[k]\n",
    "    if text_key in ['GPSLatitude', 'GPSLongitude', 'GPSAltitude']:\n",
    "      v = convert_GPS_coord(v)\n",
    "    if type(v) == bytes:\n",
    "      v = v.hex()\n",
    "    readable_gps[text_key] = v\n",
    "  return readable_gps\n",
    "\n",
    "def divide_tuple(tup):\n",
    "    try:\n",
    "        quot = tup[0]/tup[1]\n",
    "        return quot\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def convert_GPS_coord(GPS_tuple):\n",
    "    \"\"\" Converts the GPS coordinate given by exif into decimal coord\n",
    "    GPS_Tuple = (\n",
    "       (degreesNumerator, degreesDenominator), \n",
    "       (minutesNumerator, minutesDenominator), \n",
    "       (secondsNumerator, secondsDenominator)\n",
    "       )\n",
    "    \"\"\"\n",
    "    try:\n",
    "        hr_tuple = GPS_tuple[0]\n",
    "        degs = hr_tuple[0]/hr_tuple[1]\n",
    "        min_tuple = GPS_tuple[1]\n",
    "        mins = min_tuple[0]/min_tuple[1] \n",
    "        sec_tuple = GPS_tuple[2]\n",
    "        secs = sec_tuple[0]/sec_tuple[1] \n",
    "        return degs + mins/60 + secs/3600\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = parse_exif(random_img_exif) \n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in compatible_imgs:\n",
    "  img = PIL.Image.open(img_path)\n",
    "  exif = parse_exif(img._getexif())\n",
    "  if 'GPSInfo' in exif.keys():\n",
    "    print(exif['GPSInfo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Create a dataframe that holds the metadata of the images in the google drive. You do not need to store all of the metadata fields, just the ones that you may be interested in.\n",
    "\n",
    "Note that not all images will have all of the EXIF fields filled out, so you will have entries with blank values in certain columns.\n",
    "\n",
    "Note also that the GPSInfo element of EXIF is a dictionary in and of itself. Be cognizant of this when trying to access those attributes. For example, you cannot get exif_info['GPSLatitude'] directly. You have to get it as exif_info['GPSInfo']['GPSLatitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw image\n",
    "raw_img = cv2.imread(str(random_image_path),-1)\n",
    "# Convert to lower resolution for analysis speedup\n",
    "lowres_dim = 1800\n",
    "img_shape = raw_img.shape\n",
    "img = cv.resize(raw_img,\n",
    "                (int((img_shape[1]/img_shape[0])*lowres_dim), lowres_dim ),\n",
    "                interpolation=cv.INTER_CUBIC)\n",
    "plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Spaces\n",
    "Colors can be represented as a multi-dimensional space. One common way of representing colors is with RGB values. One can think of RGB as a 3d Cartesian coordinate system, where the R, G, and B values represent the x, y, and z coordinates respectively. A wide array of colors can then be expressed as tuples in this RGB space.\n",
    "\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/RGB_Cube_Show_lowgamma_cutout_a.png/400px-RGB_Cube_Show_lowgamma_cutout_a.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors look weird if you use imshow on the regular cv image\n",
    "# this is because it's in BGR instead of RGB\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to different color spaces from BGR (cv convention vs. plt convention)\n",
    "RGB_img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "grey_img = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "HSV_img = cv.cvtColor(img, cv.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct color space\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(RGB_img)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_channel = RGB_img[:,:,0]\n",
    "green_channel = RGB_img[:,:,1]\n",
    "blue_channel = RGB_img[:,:,2]\n",
    "fig = plt.figure(figsize=[10,15])\n",
    "ax1 = fig.add_subplot(3,1,1)\n",
    "ax1.imshow(red_channel,cmap='Reds_r')\n",
    "ax1.set_axis_off()\n",
    "ax2 = fig.add_subplot(3,1,2)\n",
    "ax2.imshow(green_channel,cmap='Greens_r')\n",
    "ax2.set_axis_off()\n",
    "ax3 = fig.add_subplot(3,1,3)\n",
    "ax3.imshow(blue_channel,cmap='Blues_r')\n",
    "ax3.set_axis_off()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other color spaces\n",
    "Much like how space can be represented both using cartesian coordinates and other coordinate systems, color spaces can be represented with other coordinates as well.\n",
    "\n",
    "One such alternative is the hue, saturation, value (HSV) system, which can be thought of as a cylindrical coordinate system.\n",
    "- Hue represents the color (low=violet, high=red)\n",
    "- Saturation represents the color intensity (low=grey, high=colorful)\n",
    "- Value represents brightness (low=black, high=white)\n",
    "\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/3/33/HSV_color_solid_cylinder_saturation_gray.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "For each line of the following lines, explain what is happening using comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_channel = HSV_img[:,:,0]\n",
    "saturation_channel = HSV_img[:,:,1]\n",
    "value_channel = HSV_img[:,:,2]\n",
    "fig = plt.figure(figsize=[10,15])\n",
    "ax1 = fig.add_subplot(3,1,1)\n",
    "ax1.imshow(hue_channel,cmap='Greys_r')\n",
    "ax1.set_axis_off()\n",
    "ax1.set_title('hue')\n",
    "ax2 = fig.add_subplot(3,1,2)\n",
    "ax2.imshow(saturation_channel,cmap='Greys_r')\n",
    "ax2.set_axis_off()\n",
    "ax2.set_title('saturation')\n",
    "ax3 = fig.add_subplot(3,1,3)\n",
    "ax3.imshow(value_channel,cmap='Greys_r')\n",
    "ax3.set_axis_off()\n",
    "ax3.set_title('value')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyplot's imshow assumes that the first channel is red, the second is green, and the last is blue. Thus, we can present other information in the R, G, B channels. For example, we can plot the HSV channels in the RGB channels to get a trippy picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(HSV_img)# hue -> red, saturation -> green, value -> blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "Thresholding allows you to convert pixel values that are above/below a threshold to 0 or 1.\n",
    "\n",
    "There are a ton of different [thresholding schemes](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html).\n",
    "\n",
    "There are simple thresholding schemes:\n",
    " - cv2.THRESH_BINARY\n",
    " - cv2.THRESH_BINARY_INV\n",
    " - cv2.THRESH_TRUNC\n",
    " - cv2.THRESH_TOZERO\n",
    " - cv2.THRESH_TOZERO_INV\n",
    "\n",
    "![thresholding_simple](https://docs.opencv.org/3.0-beta/_images/threshold.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original image in greyscale\n",
    "plt.imshow(grey_img, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try a simple thresholding\n",
    "# values from 128-255 get converted to 255\n",
    "# values below 128 get converted to zero\n",
    "ret, grey_thresh = cv.threshold(grey_img, 128,255, cv.THRESH_BINARY)\n",
    "plt.imshow(grey_thresh, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive thresholding\n",
    "Simple threshold manually sets the threshold point. There are a number of adaptive methods which use the values of the other pixels to determine the threshold.\n",
    "\n",
    "There are two available adaptive thresholds:\n",
    "- cv2.ADAPTIVE_THRESH_MEAN_C : threshold value is the mean of neighbourhood area.\n",
    "- cv2.ADAPTIVE_THRESH_GAUSSIAN_C : threshold value is the weighted sum of neighbourhood values where weights are a gaussian window.\n",
    "\n",
    "These take two additional arguments:\n",
    "- neighborhood: the number of pixels to use to compute the mean or gaussian\n",
    "- c: a constant that's subtracted from the window\n",
    "\n",
    "These can be tuned to adjust performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using mean\n",
    "grey_thresh = cv.adaptiveThreshold(grey_img, 255, cv.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                   cv.THRESH_BINARY, 301, 5)\n",
    "plt.imshow(grey_thresh, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gaussian\n",
    "grey_thresh = cv.adaptiveThreshold(grey_img, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                   cv.THRESH_BINARY, 501, 10)\n",
    "plt.imshow(grey_thresh, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, grey_thresh = cv.threshold(grey_img, 0,255, cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "plt.imshow(grey_thresh, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_img = cv.GaussianBlur(grey_img,(5,5),0)\n",
    "plt.imshow(blurred_img, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this reduces some of the noise\n",
    "ret, grey_thresh = cv.threshold(blurred_img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "plt.imshow(grey_thresh, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(img):\n",
    "    # Blur for lowpass\n",
    "    img = cv.GaussianBlur(img,(11,11),1)\n",
    "    # bilat_filt for further noise reduction w/ edge preservation\n",
    "    img = cv.bilateralFilter(img,5,20,20)\n",
    "    # Compute edges\n",
    "    edges = cv.Canny(img,30,60)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(get_edges(grey_img),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(get_edges(grey_thresh),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(get_edges(value_channel),cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Search up Aerial Imagery or any other form of overhead imagery (drones, satellite, planes) that may have interesting features when they are dissected using the image processing techniques we have learnt above. You can also think of the science behind colors to your advantage in this case. After you have dissected the data to the best of your ability and revealed or created something interesting with your data, go ahead and share it with the rest of the class.\n",
    "If you use the images from the lesson, see if you can use dataframes to your advantage in this scenario. You may be able to tweak values or reveal data from the dataframe that could be revealing beyond the scope of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
